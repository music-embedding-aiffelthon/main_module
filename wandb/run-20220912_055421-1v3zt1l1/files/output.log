






Epoch 1: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:27<00:00,  1.11it/s]





Epoch 2: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 3: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]





Epoch 4: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 5: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.57it/s]





Epoch 6: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.57it/s]





Epoch 7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 8: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]





Epoch 9: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.58it/s]





Epoch 10: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 11: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 12: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]





Epoch 13: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]




Epoch 14: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]





Epoch 15: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.58it/s]





Epoch 16: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:12<00:00,  2.58it/s]





Epoch 17: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.60it/s]





Epoch 18: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.59it/s]





Epoch 19: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.60it/s]






Epoch 20: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:11<00:00,  2.60it/s]
Epoch 1:   0%|                                                                                                                         | 0/31 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 81, in <module>
    trainer.linear_train_model(linear_train_dataloader, linear_test_dataloader, 'supervised', num_epochs=config['linear_evaluation_epoch'])
  File "/home/anthonypark6904/trainer_module/train_module.py", line 232, in linear_train_model
    self.linear_train_epoch(epoch_idx, train_dataloader, test_dataloader, train_type=train_type)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 245, in linear_train_epoch
    self.state, train_loss, train_accuarcy, train_top_k_accuarcy = self.linear_train_step(self.state, train_batch)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2156, in cache_miss
    out_tree, out_flat = f_pmapped_(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2032, in pmap_f
    out = pxla.xla_pmap(
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2040, in bind
    return map_bind(self, fun, *args, **params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2072, in map_bind
    outs = primitive.process(top_trace, fun, tracers, params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2043, in process
    return trace.process_map(self, fun, tracers, params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 687, in process_call
    return primitive.impl(f, *tracers, **params)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 907, in xla_pmap_impl
    compiled_fun, fingerprint = parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 295, in memoized_fun
    ans = call(fun, *args)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 935, in parallel_callable
    pmap_computation = lower_parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 1108, in lower_parallel_callable
    jaxpr, consts, replicas, parts, shards = stage_parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 1015, in stage_parallel_callable
    jaxpr, out_sharded_avals, consts = pe.trace_to_jaxpr_final(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 2176, in trace_to_jaxpr_final
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 2109, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 168, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/home/anthonypark6904/trainer_module/train_module.py", line 112, in linear_train_step
    (loss, logits), grads = grad_fn(state.params)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 1073, in value_and_grad_f
    ans, vjp_py, aux = _vjp(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2521, in _vjp
    out_primal, out_vjp, aux = ad.vjp(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py", line 135, in vjp
    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py", line 122, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 802, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 168, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/home/anthonypark6904/trainer_module/train_module.py", line 106, in loss_fn
    logits = Encoder(dilation=self.config['dilation'],
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1183, in apply
    return apply(
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 865, in wrapper
    y = fn(root, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1586, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 361, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 657, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/home/anthonypark6904/trainer_module/model/Conv2d_model.py", line 106, in __call__
    z = nn.Dense(self.n_features, name='linear_classification')(z)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 361, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 657, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py", line 186, in __call__
    kernel = self.param('kernel',
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 997, in param
    v = self.scope.param(name, init_fn, *init_args)
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 768, in param
    raise errors.ScopeParamShapeError(name, self.path_text,
jax._src.traceback_util.UnfilteredStackTrace: flax.errors.ScopeParamShapeError: Inconsistent shapes between value and initializer for parameter "kernel" in "/linear_classification": (512, 30), (512, 10). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.
--------------------
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "main.py", line 81, in <module>
    trainer.linear_train_model(linear_train_dataloader, linear_test_dataloader, 'supervised', num_epochs=config['linear_evaluation_epoch'])
  File "/home/anthonypark6904/trainer_module/train_module.py", line 232, in linear_train_model
    self.linear_train_epoch(epoch_idx, train_dataloader, test_dataloader, train_type=train_type)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 245, in linear_train_epoch
    self.state, train_loss, train_accuarcy, train_top_k_accuarcy = self.linear_train_step(self.state, train_batch)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 112, in linear_train_step
    (loss, logits), grads = grad_fn(state.params)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 106, in loss_fn
    logits = Encoder(dilation=self.config['dilation'],
  File "/home/anthonypark6904/trainer_module/model/Conv2d_model.py", line 106, in __call__
    z = nn.Dense(self.n_features, name='linear_classification')(z)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py", line 186, in __call__
    kernel = self.param('kernel',
flax.errors.ScopeParamShapeError: Inconsistent shapes between value and initializer for parameter "kernel" in "/linear_classification": (512, 30), (512, 10). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
Traceback (most recent call last):
  File "main.py", line 81, in <module>
    trainer.linear_train_model(linear_train_dataloader, linear_test_dataloader, 'supervised', num_epochs=config['linear_evaluation_epoch'])
  File "/home/anthonypark6904/trainer_module/train_module.py", line 232, in linear_train_model
    self.linear_train_epoch(epoch_idx, train_dataloader, test_dataloader, train_type=train_type)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 245, in linear_train_epoch
    self.state, train_loss, train_accuarcy, train_top_k_accuarcy = self.linear_train_step(self.state, train_batch)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2156, in cache_miss
    out_tree, out_flat = f_pmapped_(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2032, in pmap_f
    out = pxla.xla_pmap(
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2040, in bind
    return map_bind(self, fun, *args, **params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2072, in map_bind
    outs = primitive.process(top_trace, fun, tracers, params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 2043, in process
    return trace.process_map(self, fun, tracers, params)
  File "/usr/local/lib/python3.8/dist-packages/jax/core.py", line 687, in process_call
    return primitive.impl(f, *tracers, **params)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 907, in xla_pmap_impl
    compiled_fun, fingerprint = parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 295, in memoized_fun
    ans = call(fun, *args)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 935, in parallel_callable
    pmap_computation = lower_parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 1108, in lower_parallel_callable
    jaxpr, consts, replicas, parts, shards = stage_parallel_callable(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/pxla.py", line 1015, in stage_parallel_callable
    jaxpr, out_sharded_avals, consts = pe.trace_to_jaxpr_final(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 2176, in trace_to_jaxpr_final
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 2109, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 168, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/home/anthonypark6904/trainer_module/train_module.py", line 112, in linear_train_step
    (loss, logits), grads = grad_fn(state.params)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 1073, in value_and_grad_f
    ans, vjp_py, aux = _vjp(
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/api.py", line 2521, in _vjp
    out_primal, out_vjp, aux = ad.vjp(
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py", line 135, in vjp
    out_primals, pvals, jaxpr, consts, aux = linearize(traceable, *primals, has_aux=True)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/ad.py", line 122, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/profiler.py", line 294, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/jax/interpreters/partial_eval.py", line 802, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/usr/local/lib/python3.8/dist-packages/jax/linear_util.py", line 168, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/home/anthonypark6904/trainer_module/train_module.py", line 106, in loss_fn
    logits = Encoder(dilation=self.config['dilation'],
  File "/usr/local/lib/python3.8/dist-packages/jax/_src/traceback_util.py", line 162, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1183, in apply
    return apply(
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 865, in wrapper
    y = fn(root, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 1586, in scope_fn
    return fn(module.clone(parent=scope), *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 361, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 657, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/home/anthonypark6904/trainer_module/model/Conv2d_model.py", line 106, in __call__
    z = nn.Dense(self.n_features, name='linear_classification')(z)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 361, in wrapped_module_method
    return self._call_wrapped_method(fun, args, kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 657, in _call_wrapped_method
    y = fun(self, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py", line 186, in __call__
    kernel = self.param('kernel',
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/module.py", line 997, in param
    v = self.scope.param(name, init_fn, *init_args)
  File "/usr/local/lib/python3.8/dist-packages/flax/core/scope.py", line 768, in param
    raise errors.ScopeParamShapeError(name, self.path_text,
jax._src.traceback_util.UnfilteredStackTrace: flax.errors.ScopeParamShapeError: Inconsistent shapes between value and initializer for parameter "kernel" in "/linear_classification": (512, 30), (512, 10). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)
The stack trace below excludes JAX-internal frames.
The preceding is the original exception that occurred, unmodified.
--------------------
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "main.py", line 81, in <module>
    trainer.linear_train_model(linear_train_dataloader, linear_test_dataloader, 'supervised', num_epochs=config['linear_evaluation_epoch'])
  File "/home/anthonypark6904/trainer_module/train_module.py", line 232, in linear_train_model
    self.linear_train_epoch(epoch_idx, train_dataloader, test_dataloader, train_type=train_type)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 245, in linear_train_epoch
    self.state, train_loss, train_accuarcy, train_top_k_accuarcy = self.linear_train_step(self.state, train_batch)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 112, in linear_train_step
    (loss, logits), grads = grad_fn(state.params)
  File "/home/anthonypark6904/trainer_module/train_module.py", line 106, in loss_fn
    logits = Encoder(dilation=self.config['dilation'],
  File "/home/anthonypark6904/trainer_module/model/Conv2d_model.py", line 106, in __call__
    z = nn.Dense(self.n_features, name='linear_classification')(z)
  File "/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py", line 186, in __call__
    kernel = self.param('kernel',
flax.errors.ScopeParamShapeError: Inconsistent shapes between value and initializer for parameter "kernel" in "/linear_classification": (512, 30), (512, 10). (https://flax.readthedocs.io/en/latest/api_reference/flax.errors.html#flax.errors.ScopeParamShapeError)