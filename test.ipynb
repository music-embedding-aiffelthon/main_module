{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c5c717-7370-48d8-a8b2-3698336c2611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import mel_dataset\n",
    "from utils.losses import *\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# --- import model ---\n",
    "from model.supervised_model import *\n",
    "from model.Conv2d_model import Conv2d_VAE\n",
    "from model.attention import Encoder\n",
    "\n",
    "# --- import framework ---\n",
    "import flax \n",
    "from flax import jax_utils\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state, common_utils\n",
    "from flax.core.frozen_dict import unfreeze, freeze\n",
    "import jax\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.config_hook import yaml_config_hook\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc765583-bb8f-4b92-bb0d-f612704277d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = os.path.join(os.path.expanduser('~'),'trainer_module/config')     \n",
    "config = yaml_config_hook(os.path.join(config_dir, 'config.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7134c8b9-8f82-4076-a946-0f1a8268354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/home/anthonypark6904/dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97374ae2-edd3-47ab-94fc-8fb8bd6167f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load song_meta.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 707989/707989 [00:00<00:00, 801549.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load complete!\n",
      "\n",
      "Load file list...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [00:11, 14.07it/s]\n"
     ]
    }
   ],
   "source": [
    "data = mel_dataset(dataset_dir, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a14a8360-91d4-4bc6-a2c4-4afb38d9983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101169"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c5e2b5-bcb6-42ba-b4d1-8d44b402f960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c856a14d-f6c4-4675-b537-32ffe61a6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    x_train = [x for x, _ in batch]\n",
    "    y_train = [y for _, y in batch]                  \n",
    "        \n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2a6f84-e876-4912-a899-1daa2fd94454",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(data)\n",
    "train_size = int(dataset_size * 0.8)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(data, [train_size, test_size])\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=int(8/4), shuffle=True, num_workers=0, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0003a38f-3b25-48e7-9ed3-82694a7207ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8434dc5-2729-4b57-b953-63f17eefc0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "    # attributes\n",
       "    num_layers = 6\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8361a6f5-7e06-45d0-a658-8bc40b10c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state(model, shape, key, lr) -> train_state.TrainState:\n",
    "    params = model.init({'params': key, 'dropout':key}, jnp.ones(shape))\n",
    "    # Create the optimizer\n",
    "    optimizer = optax.adam(lr)\n",
    "    # Create a State\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn = model.apply,\n",
    "        tx=optimizer,\n",
    "        params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69385266-db46-453e-a2ff-16402dd2206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(32)\n",
    "state = init_state(enc, (8, 48, 1876), rng, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b12e7ed3-985d-4097-a5be-8df3251a654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      Encoder Summary                                      </span>\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path                                 </span>┃<span style=\"font-weight: bold\"> outputs             </span>┃<span style=\"font-weight: bold\"> params                     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs                               │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1876]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ Dense_0                              │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1876,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">961,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.8 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoder_norm                         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/Dropout_0             │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/LayerNorm_0           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/LayerNorm_1           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ scale: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,024 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.1 KB)</span>             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dense_0    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,050,624 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dense_1    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512]         │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">1,049,088 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 MB)</span>         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dropout_0  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dropout_1  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0            │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/key   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/out   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/query │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/value │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1,512] │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">262,144 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.0 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5                       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ last_dense                           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1876]  │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1876]        │\n",
       "│                                      │                     │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[512,1876]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ <span style=\"font-weight: bold\">962,388 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.8 MB)</span>           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ Encoder                              │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[8,48,1876]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">                                      </span>│<span style=\"font-weight: bold\">               Total </span>│<span style=\"font-weight: bold\"> 20,826,452 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(83.3 MB)</span><span style=\"font-weight: bold\">       </span>│\n",
       "└──────────────────────────────────────┴─────────────────────┴────────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                           </span>\n",
       "<span style=\"font-weight: bold\">                          Total Parameters: 20,826,452 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(83.3 MB)</span><span style=\"font-weight: bold\">                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      Encoder Summary                                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Inputs                               │ \u001b[2mfloat32\u001b[0m[8,48,1876]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ Dense_0                              │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[1876,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m961,024 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoder_norm                         │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_0                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_1                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_2                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_3                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_4                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/Dropout_0             │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/LayerNorm_0           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/LayerNorm_1           │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ scale: \u001b[2mfloat32\u001b[0m[512]        │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,024 \u001b[0m\u001b[1;2m(4.1 KB)\u001b[0m             │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dense_0    │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │ bias: \u001b[2mfloat32\u001b[0m[2048]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,2048]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,050,624 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dense_1    │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ bias: \u001b[2mfloat32\u001b[0m[512]         │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[2048,512]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m1,049,088 \u001b[0m\u001b[1;2m(4.2 MB)\u001b[0m         │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dropout_0  │ \u001b[2mfloat32\u001b[0m[8,48,2048]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0/Dropout_1  │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/MlpBlock_0            │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/key   │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/out   │ \u001b[2mfloat32\u001b[0m[8,48,512]   │ kernel: \u001b[2mfloat32\u001b[0m[1,512,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/query │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0/value │ \u001b[2mfloat32\u001b[0m[8,48,1,512] │ kernel: \u001b[2mfloat32\u001b[0m[512,1,512] │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m262,144 \u001b[0m\u001b[1;2m(1.0 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5/SelfAttention_0       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ encoderblock_5                       │ \u001b[2mfloat32\u001b[0m[8,48,512]   │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ last_dense                           │ \u001b[2mfloat32\u001b[0m[8,48,1876]  │ bias: \u001b[2mfloat32\u001b[0m[1876]        │\n",
       "│                                      │                     │ kernel: \u001b[2mfloat32\u001b[0m[512,1876]  │\n",
       "│                                      │                     │                            │\n",
       "│                                      │                     │ \u001b[1m962,388 \u001b[0m\u001b[1;2m(3.8 MB)\u001b[0m           │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│ Encoder                              │ \u001b[2mfloat32\u001b[0m[8,48,1876]  │                            │\n",
       "├──────────────────────────────────────┼─────────────────────┼────────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m                                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m20,826,452 \u001b[0m\u001b[1;2m(83.3 MB)\u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────────────────────────────────────┴─────────────────────┴────────────────────────────┘\n",
       "\u001b[1m                                                                                           \u001b[0m\n",
       "\u001b[1m                          Total Parameters: 20,826,452 \u001b[0m\u001b[1;2m(83.3 MB)\u001b[0m\u001b[1m                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.tabulate(enc, {'params': rng, 'dropout':rng})(jnp.ones((8, 48, 1876)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9ebd84e-51db-4c70-96a3-e15882ef4902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: seegong (aiffelthon). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/anthonypark6904/trainer_module/wandb/run-20220913_011811-wxh2oh37</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aiffelthon/attention/runs/wxh2oh37\" target=\"_blank\">resilient-dream-11</a></strong> to <a href=\"https://wandb.ai/aiffelthon/attention\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aiffelthon/attention/runs/wxh2oh37?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f9a57a78bb0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "        project='attention',\n",
    "        entity='aiffelthon',    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81716ca0-7ce6-40dc-a47b-9c5acf266704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @partial(jax.jit, static_argnames=['k'])\n",
    "# def top_k(logits, y,k):\n",
    "#     top_k = jax.lax.top_k(logits, k)[1]\n",
    "#     ts = jnp.argmax(y, axis=1)\n",
    "#     correct = 0\n",
    "#     for i in range(ts.shape[0]):\n",
    "#         b = (jnp.where(top_k[i,:] == ts[i], jnp.ones((top_k[i,:].shape)), 0)).sum()\n",
    "#         correct += b\n",
    "#     correct /= ts.shape[0]\n",
    "#     return correct \n",
    "\n",
    "# @jax.jit\n",
    "# def train_step(state,\n",
    "#                inputs,\n",
    "#                dropout_rng=None):\n",
    "    \n",
    "#     dropout_rng = jax.random.fold_in(dropout_rng, state.step)\n",
    "#     x, y = inputs\n",
    "#     x = x + 100\n",
    "#     def loss_fn(params):\n",
    "#         output = Encoder().apply(\n",
    "#             params,\n",
    "#             x,\n",
    "#             rngs={\"dropout\": dropout_rng})\n",
    "\n",
    "#         loss = jnp.mean(optax.softmax_cross_entropy(output, y))\n",
    "        \n",
    "#         return loss, output\n",
    "    \n",
    "#     grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "#     (loss, output), grads = grad_fn(state.params)\n",
    "#     accuracy = top_k(output, y, 1)    \n",
    "#     top_k_accuracy = top_k(output, y, 3)  \n",
    "#     new_state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "#     return new_state, loss, accuracy, top_k_accuracy\n",
    "\n",
    "# @jax.jit\n",
    "# def eval_step(state,\n",
    "#                inputs,\n",
    "#                dropout_rng=None):\n",
    "    \n",
    "#     x, y = inputs\n",
    "#     x = x + 100\n",
    "#     dropout_rng = jax.random.fold_in(dropout_rng, state.step)\n",
    "\n",
    "#     output = Encoder().apply(state.params,\n",
    "#                              x,\n",
    "#                              rngs={\"dropout\": dropout_rng})\n",
    "\n",
    "#     loss = jnp.mean(optax.softmax_cross_entropy(output, y))\n",
    "#     accuracy = top_k(output, y, 1)\n",
    "#     top_k_accuracy = top_k(output, y, 3)  \n",
    "    \n",
    "#     return loss, accuracy, top_k_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0560e3cf-0b5c-4ec2-b371-75a9c30bd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state,\n",
    "               inputs,\n",
    "               dropout_rng=None):\n",
    "    \n",
    "    dropout_rng = jax.random.fold_in(dropout_rng, state.step)\n",
    "    # inputs = jnp.swap_axes(inputs, 1, 2)\n",
    "    def loss_fn(params):\n",
    "        output = Encoder().apply(\n",
    "            params,\n",
    "            inputs,\n",
    "            rngs={\"dropout\": dropout_rng})\n",
    "\n",
    "        loss = ((inputs - output) ** 2).mean()\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grads = grad_fn(state.params)\n",
    "    new_state = state.apply_gradients(grads=grads)\n",
    "    \n",
    "    return new_state, loss\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state,\n",
    "               inputs,\n",
    "               dropout_rng=None):\n",
    "    \n",
    "    dropout_rng = jax.random.fold_in(dropout_rng, state.step)\n",
    "\n",
    "    output = Encoder().apply(state.params,\n",
    "                             inputs,\n",
    "                             rngs={\"dropout\": dropout_rng})\n",
    "\n",
    "    loss = ((inputs - output) ** 2).mean()\n",
    "\n",
    "    return output, loss\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b28ee9-c13c-415a-b243-b21ef49f5755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:58<00:00, 56.81it/s]\n",
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:19<00:00, 72.69it/s]\n",
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:18<00:00, 73.21it/s]\n",
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:17<00:00, 73.81it/s]\n",
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:17<00:00, 73.37it/s]\n",
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:18<00:00, 72.87it/s]\n",
      "Epoch 7: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:19<00:00, 72.33it/s]\n",
      "Epoch 8: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:15<00:00, 74.91it/s]\n",
      "Epoch 9: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:21<00:00, 71.74it/s]\n",
      "Epoch 10: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10117/10117 [02:14<00:00, 74.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    train_iter = iter(train_dataloader)\n",
    "    test_iter = iter(test_dataloader)\n",
    "    for i in tqdm(range(len(train_dataloader)), desc=f'Epoch {x+1}'):\n",
    "        rng, key = jax.random.split(rng)\n",
    "        x, _ = next(train_iter)\n",
    "        test_x, _ = next(test_iter)\n",
    "        \n",
    "#         x = jnp.swapaxes(x, 1, 2)        \n",
    "#         test_x = jnp.swapaxes(test_x, 1, 2)\n",
    "        \n",
    "        state, train_loss = train_step(state, x, key)\n",
    "        recon_x, test_loss = eval_step(state, test_x, key)\n",
    "        wandb.log({'train_loss': train_loss, 'test_loss': test_loss})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            fig1, ax1 = plt.subplots()\n",
    "            im1 = ax1.imshow(recon_x[0], aspect='auto', origin='lower', interpolation='none')\n",
    "            fig1.colorbar(im1)\n",
    "            fig1.savefig('recon.png')\n",
    "            plt.close(fig1)\n",
    "\n",
    "            fig2, ax2 = plt.subplots()\n",
    "            im2 = ax2.imshow(test_x[0], aspect='auto', origin='lower', interpolation='none')\n",
    "            fig2.colorbar(im2)\n",
    "            fig2.savefig('x.png')\n",
    "            plt.close(fig2)\n",
    "\n",
    "            wandb.log({'reconstruction' : [\n",
    "                        wandb.Image('recon.png')\n",
    "                        ], \n",
    "                       'original image' : [\n",
    "                        wandb.Image('x.png')\n",
    "                        ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa6d3cab-7d4a-471e-a432-369bf8f50057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [02:00<00:00, 20.97it/s]\n",
      "Epoch 2: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:06<00:00, 38.12it/s]\n",
      "Epoch 3: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.71it/s]\n",
      "Epoch 4: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.91it/s]\n",
      "Epoch 5: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.50it/s]\n",
      "Epoch 6: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:07<00:00, 37.21it/s]\n",
      "Epoch 7: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.64it/s]\n",
      "Epoch 8: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.64it/s]\n",
      "Epoch 9: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.60it/s]\n",
      "Epoch 10: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.54it/s]\n",
      "Epoch 11: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.33it/s]\n",
      "Epoch 12: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.84it/s]\n",
      "Epoch 13: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.68it/s]\n",
      "Epoch 14: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.86it/s]\n",
      "Epoch 15: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.38it/s]\n",
      "Epoch 16: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.43it/s]\n",
      "Epoch 17: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:08<00:00, 36.72it/s]\n",
      "Epoch 18: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.35it/s]\n",
      "Epoch 19: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.53it/s]\n",
      "Epoch 20: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2530/2530 [01:09<00:00, 36.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# for x in range(20):\n",
    "#     train_iter = iter(train_dataloader)\n",
    "#     test_iter = iter(test_dataloader)\n",
    "#     for i in tqdm(range(len(train_dataloader)), desc=f'Epoch {x+1}'):\n",
    "#         rng, key = jax.random.split(rng)        \n",
    "#         state, train_loss, train_accuarcy, train_top_k_accuracy = train_step(state, next(train_iter), key)\n",
    "#         test_loss, test_accuarcy, test_top_k_accuracy = eval_step(state, next(test_iter), key)\n",
    "#         wandb.log({'train_loss': train_loss, 'test_loss': test_loss, 'train_accuarcy' : train_accuarcy, 'test_accuarcy' : test_accuarcy, 'train_top_k_accuracy':train_top_k_accuracy, 'test_top_k_accuracy':test_top_k_accuracy})\n",
    "        \n",
    "\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c4d0d9e-1e76-4896-82d4-cc96556b6e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuarcy</td><td>▄▂▇▅▄▅▅▇▅▄▅▅▅▇▂▄▅▅██▇█▄█▄▇▇▄▇▇▅▅█▄▄▁█▄▅▅</td></tr><tr><td>test_loss</td><td>▃█▂▃▄▃▄▃▃▆▃▄▃▃▄▆▄▂▃▂▂▃▅▃▃▃▂▄▂▃▅▅▁▅▄▇▂▅▅▅</td></tr><tr><td>test_top_k_accuracy</td><td>▇▁▇▇▆▆▅▆▆▅▇█▆▆▅▃▄▆▇▆▇▅▅▇▅▅▇▅▆▆▄▄█▅▃▄▇▆▆▄</td></tr><tr><td>train_accuarcy</td><td>▁▂▄▅▆▆▃▅▃▂▃▅▄▆▆▆▃▆▄▆▃▆▃▅▅▆▆▆█▆▆▃▅▆▆▃▅▅▅▆</td></tr><tr><td>train_loss</td><td>█▅▂▂▂▂▂▂▃▄▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▁▁▂▂▂▁▂▃▂▃▂▁</td></tr><tr><td>train_top_k_accuracy</td><td>▁▂▅▅▆▅█▅▅▅▆▅▆█▇▇█▆▆▇▆▇█▇▇▇█▅███▇▇▇█▆▆▅█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuarcy</td><td>0.5</td></tr><tr><td>test_loss</td><td>0.98748</td></tr><tr><td>test_top_k_accuracy</td><td>1.0</td></tr><tr><td>train_accuarcy</td><td>0.28571</td></tr><tr><td>train_loss</td><td>1.86461</td></tr><tr><td>train_top_k_accuracy</td><td>0.42857</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">crimson-capybara-6</strong>: <a href=\"https://wandb.ai/aiffelthon/attention/runs/1o3mwos3\" target=\"_blank\">https://wandb.ai/aiffelthon/attention/runs/1o3mwos3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220912_164843-1o3mwos3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f578e7-4968-4da9-bad8-90e856700f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd19672-5eaf-4901-882f-082e4eb94a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e61488-be19-42be-baba-abcbe41c81d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba66a620-6ae3-49d5-9463-995e386434cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cffc34-8091-4fc0-9384-23c3c1e6758c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0576d6-dddc-4d99-88fb-19ad10464a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec32282-b9ac-4c77-a131-407fef55671b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
